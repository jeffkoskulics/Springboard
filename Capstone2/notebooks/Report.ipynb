{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report\n",
    "Estimating wine quality with objective chemical test data must never be expected to fully capture all of the factors of a subjective judgement like the quality of a wine. However, to some extent, bad wines may contain \"mistakes\", or large, undesired variance in pH, acidity, or the result of some other chemical assays. In other cases, humans simply lack sensitivity to particular parameters (such as chlorides and citric acid). \n",
    "\n",
    "In this problem, we're given an unbalanced class. The sample has lots of scores in the 5-7 range but few 3's and 4's and 8's and 9's. We would like to predict the quality of a wine sample with given measurements as features. \n",
    "\n",
    "First, consider the normalized cumulative distribution. This function represents how unbalanced our data is. Most of our data is accumulated in a narrow band of slightly-better-than-average with long tails on either side. \n",
    "\n",
    "Why am I working on this problem? Because it seemed like an easy-to-analyze data set. The file is small, the number of features is not too big, and the integer quality score seemed like it could be treated as either a regression or a classification problem. I didn't realize how poorly the models would work. Most of the predictions can be reasonably close, but there can be a few wild guesses! \n",
    "\n",
    "What we need is a model that has a confusion matrix that's concentrated around the diagonal. Plus or minus one doesn't really matter as much as errors of three or larger. The weighting score should take this into account. \n",
    "\n",
    "It looks like most of the models have a behavior that's biased well for middle-range scores. However, the lack of data at the extremes makes the fit much less steep. We can resample the data by class to boost the number of rare samples (or cut the number of middle samples). It might even be possible to simulate data of the missing category.\n",
    "\n",
    "Looks like I want to clean up a few structures. The modeling was done ad-hoc without any tuning. With tuning is the next step, to select hyperparameters. Then finally the simple model should work well enough. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
